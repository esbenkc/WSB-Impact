{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "reddit = praw.Reddit(client_id='UGk9R4L4MYqIFjA8jyTwRQ', client_secret='Hfn-gk3eZ6KGtAX0v53dzTPumE0e9g', user_agent='WebScrape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 hot posts from the MachineLearning subreddit\n",
    "hot_posts = reddit.subreddit('WallStreetBets').hot(limit=500)\n",
    "posts = [post for post in hot_posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 title  score      id  \\\n",
      "0      What Are Your Moves Tomorrow, November 09, 2021    404  qpn2qq   \n",
      "1    Most Anticipated Earnings Releases for the tra...   1582  qo23iw   \n",
      "2    Really thought I'd be a multi-millionaire already  20977  qplyoh   \n",
      "3    ðŸŽ® $GME ðŸŽ® The #1 Indicator - of you know what -...   1679  qpt7ya   \n",
      "4    Personality > Money for women (just donâ€™t be a...  16675  qpgdtr   \n",
      "..                                                 ...    ...     ...   \n",
      "495  Who is losing money when triple leverage ETFs ...     21  qn4z64   \n",
      "496  How much does Tesla need to earn in order to j...    623  qmjfa8   \n",
      "497  I SPY, QQQ TA - Friday Nov. 5, 2021 - NIO and ...     72  qmxh19   \n",
      "498                                 MRNA $840 to $9.4K     70  qmx8pu   \n",
      "499  NVDA Poor Guy Gain Porn: Why did I stop divide...     61  qmybg7   \n",
      "\n",
      "          subreddit                                                url  \\\n",
      "0    wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
      "1    wallstreetbets                https://i.redd.it/kqy0bigppzx71.png   \n",
      "2    wallstreetbets                https://i.redd.it/eysqj9ixhfy71.png   \n",
      "3    wallstreetbets                https://i.redd.it/lvt71ylu9hy71.png   \n",
      "4    wallstreetbets                    https://v.redd.it/6tqe80lu7ey71   \n",
      "..              ...                                                ...   \n",
      "495  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
      "496  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
      "497  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
      "498  wallstreetbets              https://www.reddit.com/gallery/qmx8pu   \n",
      "499  wallstreetbets                https://i.redd.it/auzm7b222ox71.png   \n",
      "\n",
      "     n_comments                                               text  \\\n",
      "0         13392  What are your moves tomorrow? Please keep the ...   \n",
      "1          1052                                                      \n",
      "2           296                                                      \n",
      "3           173                                                      \n",
      "4          1528                                                      \n",
      "..          ...                                                ...   \n",
      "495          28  I don't understand how triple leveraged ETFs w...   \n",
      "496         527  https://imgur.com/gallery/keCnGJU\\n\\nTL;DR: Te...   \n",
      "497          39  # US Market Wrap - Financial Juice\\n\\n* Stocks...   \n",
      "498          19                                                      \n",
      "499          11                                                      \n",
      "\n",
      "          created  \n",
      "0    1.636405e+09  \n",
      "1    1.636211e+09  \n",
      "2    1.636402e+09  \n",
      "3    1.636424e+09  \n",
      "4    1.636387e+09  \n",
      "..            ...  \n",
      "495  1.636094e+09  \n",
      "496  1.636029e+09  \n",
      "497  1.636068e+09  \n",
      "498  1.636067e+09  \n",
      "499  1.636070e+09  \n",
      "\n",
      "[500 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "posts_df = pd.DataFrame()\n",
    "for post in posts:\n",
    "    posts_df = posts_df.append(pd.DataFrame({'title':[post.title], \n",
    "                                             'score':[post.score], \n",
    "                                             'id':[post.id], \n",
    "                                             'subreddit':[post.subreddit], \n",
    "                                             'url':[post.url], \n",
    "                                             'n_comments':[post.num_comments], \n",
    "                                             'text':[post.selftext], \n",
    "                                             'created':[post.created]}), \n",
    "                                            ignore_index=True)\n",
    "posts_df = posts_df.reset_index(drop=True)\n",
    "print(posts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>84.258003</td>\n",
       "      <td>80.416000</td>\n",
       "      <td>83.666000</td>\n",
       "      <td>51428500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>84.900002</td>\n",
       "      <td>86.139999</td>\n",
       "      <td>84.342003</td>\n",
       "      <td>86.052002</td>\n",
       "      <td>47660500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>88.099998</td>\n",
       "      <td>90.800003</td>\n",
       "      <td>87.384003</td>\n",
       "      <td>88.601997</td>\n",
       "      <td>88892500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>88.094002</td>\n",
       "      <td>90.311996</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>90.307999</td>\n",
       "      <td>50665000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>92.279999</td>\n",
       "      <td>94.325996</td>\n",
       "      <td>90.671997</td>\n",
       "      <td>93.811996</td>\n",
       "      <td>89410500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-02</th>\n",
       "      <td>1159.359985</td>\n",
       "      <td>1208.589966</td>\n",
       "      <td>1146.000000</td>\n",
       "      <td>1172.000000</td>\n",
       "      <td>42737800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>1177.329956</td>\n",
       "      <td>1215.390015</td>\n",
       "      <td>1152.619995</td>\n",
       "      <td>1213.859985</td>\n",
       "      <td>34628500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-04</th>\n",
       "      <td>1234.410034</td>\n",
       "      <td>1243.489990</td>\n",
       "      <td>1217.000000</td>\n",
       "      <td>1229.910034</td>\n",
       "      <td>25397400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-05</th>\n",
       "      <td>1228.000000</td>\n",
       "      <td>1239.869995</td>\n",
       "      <td>1208.000000</td>\n",
       "      <td>1222.089966</td>\n",
       "      <td>21579900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>1149.790039</td>\n",
       "      <td>1197.000000</td>\n",
       "      <td>1133.000000</td>\n",
       "      <td>1162.939941</td>\n",
       "      <td>33355200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Volume  \\\n",
       "Date                                                                       \n",
       "2019-12-31    81.000000    84.258003    80.416000    83.666000  51428500   \n",
       "2020-01-02    84.900002    86.139999    84.342003    86.052002  47660500   \n",
       "2020-01-03    88.099998    90.800003    87.384003    88.601997  88892500   \n",
       "2020-01-06    88.094002    90.311996    88.000000    90.307999  50665000   \n",
       "2020-01-07    92.279999    94.325996    90.671997    93.811996  89410500   \n",
       "...                 ...          ...          ...          ...       ...   \n",
       "2021-11-02  1159.359985  1208.589966  1146.000000  1172.000000  42737800   \n",
       "2021-11-03  1177.329956  1215.390015  1152.619995  1213.859985  34628500   \n",
       "2021-11-04  1234.410034  1243.489990  1217.000000  1229.910034  25397400   \n",
       "2021-11-05  1228.000000  1239.869995  1208.000000  1222.089966  21579900   \n",
       "2021-11-08  1149.790039  1197.000000  1133.000000  1162.939941  33355200   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2019-12-31          0           0.0  \n",
       "2020-01-02          0           0.0  \n",
       "2020-01-03          0           0.0  \n",
       "2020-01-06          0           0.0  \n",
       "2020-01-07          0           0.0  \n",
       "...               ...           ...  \n",
       "2021-11-02          0           0.0  \n",
       "2021-11-03          0           0.0  \n",
       "2021-11-04          0           0.0  \n",
       "2021-11-05          0           0.0  \n",
       "2021-11-08          0           0.0  \n",
       "\n",
       "[469 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "stocks = ['TSLA', 'AMD', 'SPY', 'AMD', 'SDC','GME','PYPL','NVDA','AMC','LCID','PLTR','CLOV','TLRY','RBLX','NEGG','PTON','FB','RIOT','MARA','CLF','WISH','NIO','SPCE','SNDL','CHPT','AMZN','HOOD','SOFI','HUT','QQQ','BB']\n",
    "\n",
    "ticker_data = yf.Ticker(stocks[0])\n",
    "ticker_df = ticker_data.history(period='1d', start='2020-01-01')\n",
    "\n",
    "ticker_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-12-31', '2020-01-02', '2020-01-03', '2020-01-06',\n",
       "               '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10',\n",
       "               '2020-01-13', '2020-01-14',\n",
       "               ...\n",
       "               '2021-10-26', '2021-10-27', '2021-10-28', '2021-10-29',\n",
       "               '2021-11-01', '2021-11-02', '2021-11-03', '2021-11-04',\n",
       "               '2021-11-05', '2021-11-08'],\n",
       "              dtype='datetime64[ns]', name='Date', length=469, freq=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df['created']\n",
    "ticker_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MachineLearning subreddit data\n",
    "ml_subreddit = reddit.subreddit('MachineLearning')\n",
    "\n",
    "print(ml_subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.comments.replace_more(limit=0)\n",
    "for top_level_comment in submission.comments:\n",
    "    print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.comments.replace_more(limit=0)\n",
    "for comment in submission.comments.list():\n",
    "    print(comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'write_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-27b27f0f4b3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title_body'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSIA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compound'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reddit_wsb_add_sentiment.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'write_csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_wsb_add.csv')\n",
    "SIA = vs()\n",
    "df['title_body'] = [str(title) + ' ' + str(body) for title, body in zip(df['title'], df['body'])]\n",
    "df['sentiment'] = df['title_body'].apply(lambda x: SIA.polarity_scores(text=x)['compound'])\n",
    "\n",
    "df.write_csv('reddit_wsb_add_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"reddit_wsb_add_sentiment.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
